{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/fetal-health-classification/fetal_health.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/fetal-health-classification/fetal_health.csv\")","metadata":{"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   baseline value  accelerations  fetal_movement  uterine_contractions  \\\n0           120.0          0.000             0.0                 0.000   \n1           132.0          0.006             0.0                 0.006   \n2           133.0          0.003             0.0                 0.008   \n3           134.0          0.003             0.0                 0.008   \n4           132.0          0.007             0.0                 0.008   \n\n   light_decelerations  severe_decelerations  prolongued_decelerations  \\\n0                0.000                   0.0                       0.0   \n1                0.003                   0.0                       0.0   \n2                0.003                   0.0                       0.0   \n3                0.003                   0.0                       0.0   \n4                0.000                   0.0                       0.0   \n\n   abnormal_short_term_variability  mean_value_of_short_term_variability  \\\n0                             73.0                                   0.5   \n1                             17.0                                   2.1   \n2                             16.0                                   2.1   \n3                             16.0                                   2.4   \n4                             16.0                                   2.4   \n\n   percentage_of_time_with_abnormal_long_term_variability  ...  histogram_min  \\\n0                                               43.0       ...           62.0   \n1                                                0.0       ...           68.0   \n2                                                0.0       ...           68.0   \n3                                                0.0       ...           53.0   \n4                                                0.0       ...           53.0   \n\n   histogram_max  histogram_number_of_peaks  histogram_number_of_zeroes  \\\n0          126.0                        2.0                         0.0   \n1          198.0                        6.0                         1.0   \n2          198.0                        5.0                         1.0   \n3          170.0                       11.0                         0.0   \n4          170.0                        9.0                         0.0   \n\n   histogram_mode  histogram_mean  histogram_median  histogram_variance  \\\n0           120.0           137.0             121.0                73.0   \n1           141.0           136.0             140.0                12.0   \n2           141.0           135.0             138.0                13.0   \n3           137.0           134.0             137.0                13.0   \n4           137.0           136.0             138.0                11.0   \n\n   histogram_tendency  fetal_health  \n0                 1.0           2.0  \n1                 0.0           1.0  \n2                 0.0           1.0  \n3                 1.0           1.0  \n4                 1.0           1.0  \n\n[5 rows x 22 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>baseline value</th>\n      <th>accelerations</th>\n      <th>fetal_movement</th>\n      <th>uterine_contractions</th>\n      <th>light_decelerations</th>\n      <th>severe_decelerations</th>\n      <th>prolongued_decelerations</th>\n      <th>abnormal_short_term_variability</th>\n      <th>mean_value_of_short_term_variability</th>\n      <th>percentage_of_time_with_abnormal_long_term_variability</th>\n      <th>...</th>\n      <th>histogram_min</th>\n      <th>histogram_max</th>\n      <th>histogram_number_of_peaks</th>\n      <th>histogram_number_of_zeroes</th>\n      <th>histogram_mode</th>\n      <th>histogram_mean</th>\n      <th>histogram_median</th>\n      <th>histogram_variance</th>\n      <th>histogram_tendency</th>\n      <th>fetal_health</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>120.0</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>73.0</td>\n      <td>0.5</td>\n      <td>43.0</td>\n      <td>...</td>\n      <td>62.0</td>\n      <td>126.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>120.0</td>\n      <td>137.0</td>\n      <td>121.0</td>\n      <td>73.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>132.0</td>\n      <td>0.006</td>\n      <td>0.0</td>\n      <td>0.006</td>\n      <td>0.003</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>17.0</td>\n      <td>2.1</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>68.0</td>\n      <td>198.0</td>\n      <td>6.0</td>\n      <td>1.0</td>\n      <td>141.0</td>\n      <td>136.0</td>\n      <td>140.0</td>\n      <td>12.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>133.0</td>\n      <td>0.003</td>\n      <td>0.0</td>\n      <td>0.008</td>\n      <td>0.003</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>16.0</td>\n      <td>2.1</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>68.0</td>\n      <td>198.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>141.0</td>\n      <td>135.0</td>\n      <td>138.0</td>\n      <td>13.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>134.0</td>\n      <td>0.003</td>\n      <td>0.0</td>\n      <td>0.008</td>\n      <td>0.003</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>16.0</td>\n      <td>2.4</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>53.0</td>\n      <td>170.0</td>\n      <td>11.0</td>\n      <td>0.0</td>\n      <td>137.0</td>\n      <td>134.0</td>\n      <td>137.0</td>\n      <td>13.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>132.0</td>\n      <td>0.007</td>\n      <td>0.0</td>\n      <td>0.008</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>16.0</td>\n      <td>2.4</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>53.0</td>\n      <td>170.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>137.0</td>\n      <td>136.0</td>\n      <td>138.0</td>\n      <td>11.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 22 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"list(set(data))","metadata":{"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"['fetal_movement',\n 'prolongued_decelerations',\n 'uterine_contractions',\n 'percentage_of_time_with_abnormal_long_term_variability',\n 'mean_value_of_short_term_variability',\n 'histogram_median',\n 'fetal_health',\n 'histogram_max',\n 'histogram_tendency',\n 'baseline value',\n 'accelerations',\n 'mean_value_of_long_term_variability',\n 'histogram_mean',\n 'histogram_number_of_zeroes',\n 'histogram_number_of_peaks',\n 'severe_decelerations',\n 'histogram_min',\n 'light_decelerations',\n 'histogram_mode',\n 'abnormal_short_term_variability',\n 'histogram_width',\n 'histogram_variance']"},"metadata":{}}]},{"cell_type":"code","source":"X = data.drop(['fetal_health'], axis=1)\nY = data['fetal_health']\n\nX.shape","metadata":{"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(2126, 21)"},"metadata":{}}]},{"cell_type":"code","source":"X = X.values\nY = Y.values","metadata":{"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nxTrain, xTest, yTrain, yTest = train_test_split(X, Y, test_size = 0.05, random_state = 365)","metadata":{"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression()\nlogreg.fit(xTrain,yTrain)\ny_pred=logreg.predict(xTest)\nfrom sklearn import metrics\nprint(\"Accuracy:\",metrics.accuracy_score(yTest, y_pred))","metadata":{"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Accuracy: 0.8411214953271028\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","output_type":"stream"}]},{"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\nmodel = XGBClassifier()\nmodel.fit(xTrain, yTrain)\ny_pred=model.predict(xTest)\nprint(accuracy_score(yTest, y_pred)*100)","metadata":{"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n","output_type":"stream"},{"name":"stdout","text":"[15:40:41] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n96.26168224299066\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier(max_depth=50, random_state=42)\nclf.fit(xTrain, yTrain)\ny_pred=clf.predict(xTest)\nprint(accuracy_score(yTest, y_pred)*100)","metadata":{"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"93.45794392523365\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\nClf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\nClf.fit(xTrain, yTrain)\ny_pred=Clf.predict(xTest)\nprint(accuracy_score(yTest, y_pred)*100)","metadata":{"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"91.58878504672897\n","output_type":"stream"}]}]}